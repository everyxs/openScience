"Tag","PaperId","AuthorIdsOrder","AuthorNamesOrder","FoSNames","Year","DocType","DisplayName","Publisher","Doi","OriginalTitle","EstimatedCitation","IndexedAbstract"
"Reproducibility",2325177196,"2320257111","S.H. Berner","cadaver; medicine; radiography; reproducibility; surgery; radiology",2006,"Journal",NA,NA,"10.1016/S1551-7977(08)70092-X","A Cadaver Model to Evaluate the Accuracy and Reproducibility of Plain Radiograph Step and Gap Measurements for Intra-Articular Fracture of the Distal Radius",0,NA
"Reproducibility",2012047325,"2691205855","Wayne E. Hensley","psychology; source credibility; social psychology; reproducibility; criticism",1974,"Journal","Communication Monographs","Taylor & Francis Group","10.1080/03637757409375851","A criticism of “dimensions of source credibility: A test for reproducibility”",2,NA
"Reproducibility",2733058137,"2572492543; 2776847356; 2779323030; 2780511777","S.A. Rivkees; D.A. Hall; P.A. Boepple; J.D. Crawford","pathology; reproducibility; medicine",1987,"Journal","The Journal of Urology",NA,"10.1016/S0022-5347(17)43708-6","Accuracy and Reproducibility of Clinical Measures of Testicular Volume",1,NA
"Reproducibility",2284191284,"2087863783","Richard R J Cousley","orthodontics; reproducibility; medicine",2015,"Journal","Journal of Orthodontics","Taylor & Francis","10.1080/14653125.2015.1122915","Accuracy and Reproducibility Of Linear Measurements Of Resin, Plaster, Digital and Printed Study-Models",0,NA
"OpenScience",2024986130,"705885879; 2114464965; 2267980870","Amye Kenall; Simon Harold; Christopher Foote","data sharing; open data; ecology and evolutionary biology; open science; entomology; biology; evolutionary biology",2014,"Journal","BMC Evolutionary Biology","BioMed Central Ltd","10.1186/1471-2148-14-66","An open future for ecological and evolutionary data",2,"As part of BioMed Central’s open science mission, we are pleased to announce that two of our journals have integrated with the open data repository Dryad. Authors submitting their research to either BMC Ecology or BMC Evolutionary Biology will now have the opportunity to deposit their data directly into the Dryad archive and will receive a permanent, citable link to their dataset. Although this does not affect any of our current data deposition policies at these journals, we hope to encourage a more widespread adoption of open data sharing in the fields of ecology and evolutionary biology by facilitating this process for our authors. We also take this opportunity to discuss some of the wider issues that may concern researchers when making their data openly available. Although we offer a number of positive examples from different fields of biology, we also recognise that reticence to data sharing still exists, and that change must be driven from within research communities in order to create future science that is fit for purpose in the digital age."
"Reproducibility",2100555847,"705885879; 1976589559; 2412316283; 2132292370; 2497373859; 2160563883; 2505586523","Amye Kenall; Scott Edmunds; Laurie Goodman; Liz Bal; Louisa Flintoft; Daniel R Shanahan; Tim Shipley","research design; checklist; reproducibility; genetics; biology; replicate; bioinformatics",2015,"Journal","Genome Biology","BioMed Central","10.1186/s13059-015-0710-5","Better reporting for better research: a checklist for reproducibility",4,"How easy is it to reproduce or replicate the findings of a published paper? In 2013 one researcher, Phil Bourne, asked just this. How easy would it be to reproduce the results of a computational biology paper? [1]. The answer: 280 hours. Such a number is surprising, given the theoretical reproducibility of computational research and given Bourne was attempting to reproduce work done in his own lab. Now at the National Institutes of Health (NIH) as Associate Director of Data Sciences, Bourne is concerned with the reproducibility of all NIH funded work, not just his own—and the problem is large. In addition to work in computational biology (which theoretically should be more easily reproducible than “wet lab” work), hallmark papers in cancer through to psychology have been flagged as largely unreproducible [2, 3]. Closer to home, GigaScience has carried out similar work to quantify reproducibility in their content. Despite being scrutinized and tested by seven referees, it still took about half a man-month worth of resources to reproduce the results reported in just one of the tables [4]. “Reproducibility” is now increasingly on the radar of funders and is making its rounds in the wider media as well, with concerns of reproducibility making headlines at The Economist [5] and New York Times [6], amongst other outlets."
"Reproducibility",1990981932,"705885879; 1976589559; 2412316283; 2132292370; 2497373859; 2160563883; 2505586523","Amye Kenall; Scott Edmunds; Laurie Goodman; Liz Bal; Louisa Flintoft; Daniel R Shanahan; Tim Shipley","checklist; reproducibility; bioinformatics; computer science; replicate",2015,"Journal","GigaScience","BioMed Central Ltd","10.1186/s13742-015-0071-8","Better reporting for better research: a checklist for reproducibility",4,"How easy is it to reproduce or replicate the findings of a published paper? In 2013 one researcher, Phil Bourne, asked just this. How easy would it be to reproduce the results of a computational biology paper? [1]. The answer: 280 hours. Such a number is surprising, given the theoretical reproducibility of computational research and given Bourne was attempting to reproduce work done in his own lab. Now at the National Institutes of Health (NIH) as Associate Director of Data Sciences, Bourne is concerned with the reproducibility of all NIH funded work, not just his own—and the problem is large. In addition to work in computational biology (which theoretically should be more easily reproducible than “wet lab” work), hallmark papers in cancer through to psychology have been flagged as largely unreproducible [2, 3]. Closer to home, GigaScience has carried out similar work to quantify reproducibility in their content. Despite being scrutinized and tested by seven referees, it still took about half a man-month worth of resources to reproduce the results reported in just one of the tables [4]. “Reproducibility” is now increasingly on the radar of funders and is making its rounds in the wider media as well, with concerns of reproducibility making headlines at The Economist [5] and New York Times [6], amongst other outlets."
"Reproducibility",2620737572,"2420897258; 2040367464; 2022178797","Matti T. J. Heino; Eiko I. Fried; Etienne P. LeBel","reproducibility; social psychology; psychology; complex systems",2017,"Journal","Frontiers in Psychology","Frontiers","10.3389/fpsyg.2017.01004","Commentary: Reproducibility in Psychological Science: When Do Psychological Phenomena Exist?",0,NA
"Reproducibility",2034972036,"2667069942","Harvey J. Motulsky","data science; statistical hypothesis testing; computer science; standard error; reproducibility; text mining; data mining",2015,"Journal","Pharmacology Research & Perspectives","Pharmacol Res Perspect","10.1002/prp2.93","Common misconceptions about data analysis and statistics",8,"Ideally, any experienced investigator with the right tools should be able to reproduce a finding published in a peer-reviewed biomedical science journal. In fact, the reproducibility of a large percentage of published findings has been questioned. Undoubtedly, there are many reasons for this, but one reason may be that investigators fool themselves due to a poor understanding of statistical concepts. In particular, investigators often make these mistakes: (1) P-Hacking. This is when you reanalyze a data set in many different ways, or perhaps reanalyze with additional replicates, until you get the result you want. (2) Overemphasis on P values rather than on the actual size of the observed effect. (3) Overuse of statistical hypothesis testing, and being seduced by the word “significant”. (4) Overreliance on standard errors, which are often misunderstood."
"Reproducibility",1971489609,"2633604498","Harvey Motulsky","statistics; standard error; statistical hypothesis testing; medicine; reproducibility",2014,"Journal","Naunyn-schmiedebergs Archives of Pharmacology","Naunyn Schmiedebergs Arch Pharmacol","10.1007/s00210-014-1037-6","Common misconceptions about data analysis and statistics",14,"Ideally, any experienced investigator with the right tools should be able to reproduce a finding published in a peer-reviewed biomedical science journal. In fact, the reproducibility of a large percentage of published findings has been questioned. Undoubtedly, there are many reasons for this, but one reason maybe that investigators fool themselves due to a poor understanding of statistical concepts. In particular, investigators often make these mistakes: 1. P-Hacking. This is when you reanalyze a data set in many different ways, or perhaps reanalyze with additional replicates, until you get the result you want. 2. Overemphasis on P values rather than on the actual size of the observed effect. 3. Overuse of statistical hypothesis testing, and being seduced by the word “significant”. 4. Overreliance on standard errors, which are often misunderstood."
"Reproducibility",2058618110,"2768209340","Emilie Marcus","genetics; reproducibility; transparency; knowledge management; credibility; biology",2014,"Journal","Molecular Cell","Elsevier","10.1016/j.molcel.2014.11.012","Credibility and reproducibility.",1,"Credibility is everything for science, and it is built over time in both obvious and subtle ways. It is how we interact with colleagues and collaborators. It is how generously and openly we share reagents and how we mentor students and postdocs. It is how we review each other’s papers, and it is how we credit others' work. It is the way we educate and inform the public that funds us. It is the way we document and store our data. And it is the rigor, transparency, and attention we invest in designing, conducting, and reporting experiments."
"Reproducibility",2059692560,"1293640941; 2028454606; 666554414; 2161285743","Rodolfo Montironi; Marina Scarpelli; Antonio Lopez-Beltran; Liang Cheng","pathology; medicine; reproducibility",2009,"Journal","European Urology","Eur Urol","10.1016/j.eururo.2008.04.075","Editorial Comment on: Cytological Punctures in the Diagnosis of Renal Tumours: A Study on Accuracy and Reproducibility",0,NA
"Reproducibility",1972790144,"2466989213","Eric Meuleman","medicine; reproducibility; urology",2007,"Journal","European Urology","Eur Urol","10.1016/j.eururo.2007.01.076","Editorial Comment on: The Immediate and 6-mo Reproducibility of Pressure–Flow Studies in Men with Benign Prostatic Enlargement",0,NA
"Reproducibility",2064016264,"2577662909","Keith Snell","reproducibility; analytical chemistry; materials science",1988,"Journal","Nature","Nature Publishing Group","10.1038/334559c0","Evidence of non-reproducibility",0,NA
"Reproducibility",1994937871,"2704818539","Jeanclare Seagrave","analytical chemistry; materials science; reproducibility",1988,"Journal","Nature","Nature Publishing Group","10.1038/334559a0","Evidence of non-reproducibility",4,NA
"Reproducibility",2605527249,"2522234740; 2401913112","Kazuo Sano; Hiromitsu Ishii","physics; computer vision; artificial intelligence; reproducibility",2002,"Journal","Journal of The Illuminating Engineering Institute of Japan","一般社団法人 照明学会","10.2150/jieij1980.86.2_67","Identification of Coloring Agents Causing Poor Coloring Reproducibility in Computerized Color Matching",0,NA
"Reproducibility",1967990099,"2491578274","David L. Page","general surgery; radiology; medicine; reproducibility",2005,"Journal","Breast Diseases: A Year Book Quarterly",NA,"10.1016/S1043-321X(05)80170-5","Improving the Reproducibility of Diagnosing Micrometastases and Isolated Tumor Cells",0,NA
"Reproducibility",2318955727,"2653667958; 2646808135; 2651657820; 2687886206; 2676442317; 2485740020; 2651964484","Sm Lobmaier; M Cruz-Lemini; B Valenzuela-Alcaraz; Ju Ortiz; Jm Martinez; E. Gratacós; F Crispi","radiology; obstetrics; pediatrics; medicine; reproducibility; repeatability",2014,"Journal","Geburtshilfe Und Frauenheilkunde",NA,"10.1055/s-0034-1388045","Influence of equipment and settings on myocardial performance index repeatability and definition of settings to achieve optimal reproducibility",0,NA
"Reproducibility",2009649641,"2141706502; 259477609; 2015127353; 2229712173; 2020384923; 2777378965","Joan-Carles Arce; Søren Ziebe; Kersti Lundin; R. Janssens; L. Helmgaard; P. Sørensen","obstetrics; embryo quality; medicine; radiology; reproducibility",2005,"Journal","Fertility and Sterility","Elsevier","10.1016/j.fertnstert.2005.07.250","Interobserver Agreement and Intraobserver Reproducibility of Embryo Quality Assessments",0,NA
"Reproducibility",2317589598,"2650686529; 2051862677; 2158812809; 2050622594; 2513997452","M. Asrar Ul Haq; Vivek Mutha; Simon Stewart; M. Carrington; Chun Wai Wong","reproducibility; diastolic function; cardiology; medicine; internal medicine",2013,"Journal","European Heart Journal",NA,"10.1093/eurheartj/eht308.P1117","Interstudy reproducibility of echocardiographic parameters in the serial assessment of left ventricular diastolic function",0,NA
"Reproducibility",2026260649,"2690453826; 2319929540; 2713479467; 2515658936; 2498083367","Pa. Torzilli; Ra. Panariello; A. Forbes; Tj. Santner; Rf. Warren","medicine; physical therapy; reproducibility",1992,"Journal","Clinical Journal of Sport Medicine",NA,"10.1097/00042752-199204000-00014","MEASUREMENT REPRODUCIBILITY OF TWO COMMERCIAL KNEE TEST DEVICES",0,NA
"Reproducibility",2063168916,"1130234009; 2599490930; 2442885704; 2716057424; 123077910","Morten Essendrop; Irina Maul; Thomas Läubli; Hilkka Riihimäki; Bente Schibye","systematic review; data mining; reproducibility; medline; physical therapy; medicine; information retrieval; functional testing",2003,"Journal","Physical Therapy in Sport","Elsevier","10.1016/S1466-853X(03)00072-5","Measures of low back function: a review of reproducibility studies",3,"Abstract Objective . The objective of the present study was to make a systematic literature review with preset quality criteria concerning reproducibility of the tests of the low back regarding strength, endurance and range of motion. Design . Literature in Medline and local databases was reviewed for articles concerning the reproducibility of strength, endurance, and range of motion measurements. Background . Measures of low back function are widely used, and are important for both clinical and research purposes in relation to low back problems. A review of the reproducibility of these tests has not previously been made. Methods . After extensive discussion among all the authors, general evaluation parameters were defined for the quality assessment. Every study was graded from 0 to 2 for each parameter. Parameters evaluated were: number of subjects, subject description, method description, test/retest interval, description of results, and statistics. Results . The literature search revealed a total of 79 studies. Most studies suffered from methodological weaknesses and only 11 studies received 10 or more quality points (maximum 14). The results from the highest graded studies are highlighted. Conclusions . It may be concluded that there is a considerable lack of information about the reproducibility of functional measures for the low back, and, therefore, a recommendation for consensus is difficult. However, most tests performed in the sagittal plane are reliable for use on groups. Relevance . Measures of low back function are thought to be of great importance for clinicians, and low back researchers in general. A review of reproducibility will be helpful both as a survey of tests, and to provide information on the usefulness in relation to the level of reproducibility."
"OpenScience",2751591353,"2752293879","Doreen Siegfried","open science; art; library science",2017,"Journal",NA,NA,"10.15358/0340-1650-2017-7-8-54","Open Science: Das neue Gold von Wissenschaft sind Forschungsdaten",0,NA
"Reproducibility",2333058176,"2679623471; 2591534458; 2590667453; 2590743729; 2591198797; 2589869046; 2591106474; 2779245310","Jun Okamoto; Yu Kumasaka; Kazuya Kawamura; Tomoyuki Matsumoto; Seiji Kubo; Hirotsugu Muratsu; Masahiro Kurosaka; Masakatsu G. Fujie","biological engineering; physical examination; reproducibility; medicine",2011,"Journal","Transactions of the Japan Society of Mechanical Engineers. C","Japan Society of Mechanical Engineers","10.1299/kikaic.77.138","Orthopaedic physical examination assisting system for improvement of accuracy and reproducibility of knee laxity diagnosis",0,NA
"Reproducibility",2040930467,"2646710360; 1695394352; 1699392357; 2462643194; 1976442374","Frank H. Comhaire; Ann C. C. Criel; Christian A. A. Dassy; Pierre G. J. Guévar; Frédéric Snaps","medicine; radiology; reproducibility; pathology",2009,"Journal","Javma-journal of The American Veterinary Medical Association",NA,"10.2460/javma.234.4.485","Precision, reproducibility, and clinical usefulness of measuring the Norberg angle by means of computerized image analysis",0,NA
"Reproducibility",2060740315,"2160799017; 2306077282; 2690672039; 2687595214; 2621384675","Birgit Guldhammer Skov; A.F. Lauritzen; F.R. Hirsch; T. Skov; H.W. Nielsen","reproducibility; antibody; pathology; medicine",2007,"Journal","Histopathology","Blackwell Publishing Ltd","10.1111/j.1365-2559.1995.tb00266.x","Predictive value and reproducibility of immunoreactive antibodies",0,NA
"Reproducibility",2496947649,"2628403006","Kenneth Hamma","information retrieval; reproducibility; art; public domain",2006,"Journal","Art libraries journal",NA,"10.1017/S0307472200014541","Public domain art in an age of easier mechanical reproducibility",1,NA
"Reproducibility",2140646771,"2575102326","Jesus Alcazar","inorganic chemistry; reproducibility; microwave; chemistry; organic chemistry",2005,"Journal","ChemInform","WILEY‐VCH Verlag","10.1002/chin.200542047","Reproducibility Across Microwave Instruments: Preparation of a Set of 24 Compounds on a Multiwell Plate under Temperature-Controlled Conditions.",10,NA
"Reproducibility",2322397178,"2564778043; 2646673633; 1975541664","Lori A. Karol; E. G. Sheffield; Kevin Crawford","medicine; instability; down syndrome; physical therapy; reproducibility",1997,"Journal","Journal of Pediatric Orthopaedics",NA,"10.1097/01241398-199705000-00058","REPRODUCIBILITY IN THE MEASUREMENT OF ATLANTO-OCCIPITAL INSTABILITY IN CHILDREN WITH DOWN SYNDROME",0,NA
"Reproducibility",2157859805,"2668304753; 2660475847; 2196531592","A. Dawson; N.B.N. Ibrahim; Allen R. Gibbs","pathology; reproducibility; medicine",1995,"Journal","Histopathology","Blackwell Publishing Ltd","10.1111/j.1365-2559.1995.tb00335.x","Reproducibility of a of thymic epithelial his togene t ic classification tumours",0,NA
"Reproducibility",1966500413,"2669114752; 2701469599; 2666509545; 2709804849","B. O. Osinusi; A. J. Hall; A. H. Adam; J. E. E. Fleming","radiology; reproducibility; scanner; medicine; obstetrics",1981,"Journal","Obstetrical & Gynecological Survey",NA,"10.1097/00006254-198103000-00002","Reproducibility of Biparietal Diameter Measurements Obtained with a Real-Time Scanner",0,NA
"Reproducibility",2771780683,"2168577915; 2148299636","Maddalena De Bernardo; Nicola Rosa","medicine; reproducibility; radiology; surgery",2017,"Journal","Journal of Glaucoma",NA,"10.1097/IJG.0000000000000843","Reproducibility of Central Corneal Thickness Measurements in Healthy and Glaucomatous Eyes",0,NA
"Reproducibility",2323201885,"1971432396","R.C. Cantu","medicine; physical therapy; neuropsychology; football; elite; norwegian; physical medicine and rehabilitation; reproducibility",2007,"Journal","Yearbook of Sports Medicine",NA,"10.1016/S0162-0908(08)70030-8","Reproducibility of computer based neuropsychological testing among Norwegian elite football players",0,NA
"Reproducibility",2088841575,"2717614539","M Debruyne","reproducibility; physical therapy; medicine; coding",1998,"Journal","Journal of Cardiothoracic and Vascular Anesthesia",NA,"10.1016/S1053-0770(98)90133-1","Reproducibility of computerized ecg measurements and coding in a nonhospitalized elderly population",0,NA
"Reproducibility",2780086612,"2133039009; 2152926006; 2121463927","Oscar H. Del Brutto; Hector H. Garcia; Javier A. Bustos","biology; immunology; neurocysticercosis; pathology; reproducibility",2017,"Journal","American Journal of Tropical Medicine and Hygiene",NA,"10.4269/ajtmh.17-0724b","Reproducibility of Diagnostic Criteria for Ventricular Neurocysticercosis",0,NA
"Reproducibility",2133801035,"1974944867; 2038459021; 275691885","Wolfgang Uter; Annette Pfahlberg; Olaf Gefeller","dermatology; reproducibility; medicine",2004,"Journal","Contact Dermatitis","Munksgaard International Publishers","10.1111/j.0105-1873.2004.00393.x","Reproducibility of patch tests",7,NA
"Reproducibility",2033597291,"2700886539","David Spencer","reproducibility; spirometry; radiology; anesthesia; medicine",1992,"Journal","The American review of respiratory disease","American Lung Association","10.1164/ajrccm/145.1.236","Spirometry: Quality Control and Reproducibility Criteria",1,NA
"Reproducibility",2110787577,"2645247999","Ben Carterette","data mining; statistical significance; biomedical sciences; text retrieval conference; statistical hypothesis testing; information retrieval; reproducibility; computer science",2014,"Conference",NA,"ACM","10.1145/2600428.2602292","Statistical significance testing in information retrieval: theory and practice",1,"The past 20 years have seen a great improvement in the rigor of information retrieval experimentation, due primarily to two factors: high-quality, public, portable test collections such as those produced by TREC (the Text REtrieval Conference), and the increased practice of statistical hypothesis testing to determine whether measured improvements can be ascribed to something other than random chance. Together these create a very useful standard for reviewers, program committees, and journal editors; work in information retrieval (IR) increasingly cannot be published unless it has been evaluated using a well-constructed test collection and shown to produce a statistically significant improvement over a good baseline. But, as the saying goes, any tool sharp enough to be useful is also sharp enough to be dangerous. Statistical tests of significance are widely misunderstood. Most researchers and developers treat them as a ""black box"": evaluation results go in and a p-value comes out. But because significance is such an important factor in determining what research directions to explore and what is published, using p-values obtained without thought can have consequences for everyone doing research in IR. Ioannidis has argued that the main consequence in the biomedical sciences is that most published research findings are false; could that be the case in IR as well?"
"Reproducibility",2318463192,"2679623471; 2591534458; 2117165463; 2160173928; 2125455454; 2091179548; 2021010695; 2116380018","Jun Okamoto; Yu Kumasaka; Kazuya Kawamura; Tomoyuki Matsumoto; Seiji Kubo; Hirotsugu Muratsu; Masahiro Kurosaka; Masakatsu G. Fujie","reproducibility; computer science; biological engineering; physical examination; sampling error",2011,"Journal","Transactions of the Japan Society of Mechanical Engineers. C","Japan Society of Mechanical Engineers","10.1299/kikaic.77.3780","Study of anatomical landmark sampling error effect on motion measurement reproducibility for Orthopaedic physical examination assisting system",0,NA
"Reproducibility",2113375489,"2092620728; 2739804707","M. T. Fernández Pareja; A. García Pablos","laser scanning; engineering; computer vision; artificial intelligence; repeatability; reproducibility; simulation; calibration",2013,"Conference",NA,"EDP Sciences","10.1051/metrology/201306001","Terrestrial Laser Scanner (TLS) equipment calibration",1,"This study's aim is to develop the measurement procedures to evaluate the quality of the observations made using TLS equipment. In addition, it seeks to estimate an uncertainty value allowing the users to know the reliability of the instrument measurements. The intention is to describe a working reproducible methodology without the need for a very complex infrastructure and based on ISO criteria. To achieve this, several TLS equipment based on different measurement principles were used. This study provides a good approach to the repeatability and reproducibility of the measurements to determine how the different measurements of the same measurand match."
"Reproducibility",2091644483,"2281638738; 2434205300","Xingdong Shen; Gang Dong","ovality; transfer function; clamping; clamp; cylinder; reproducibility; computer science; control engineering",2010,"Conference",NA,"International Society for Optics and Photonics","10.1117/12.887825","The calculation of the reproducibility error in the technological system with the clamp on the gas power",0,"The paper deduced a calculation formula by the classic control theory on the Reproducibility Error of parts
processing in the technology system, the flexible clamp system , with the clamping device on the gas power, and
analyzed its influencing factor with examples, the Reproducibility Error law: The larger the diameter of the
cylinder, the smaller the error; the slower the tool speed, (k values smaller), the smaller the error."
"Reproducibility",2482392649,"2131821156; 2157432659; 2170398916; 2170215785","Ruth G. Shaw; Allen J. Moore; Mohamed A. F. Noor; Michael G. Ritchie","biology; credibility; vitality; documentation; transparency; reproducibility; management science; generality",2016,"Journal","Ecology and Evolution","John Wiley and Sons Ltd","10.1002/ece3.2291","Transparency and reproducibility in evolutionary research",0,"The vitality of the science of evolutionary biology depends on new research findings that continually advance understanding, and the sound approaches by which those findings are obtained must be clearly documented. This transparency of documentation crucially grounds others' assessment of the credibility of the inferences and interpretations. It is also essential to attempts of future scientists, in conducting independent research, to validate the findings and assess their generality, advancing the field still further. These core aspects of science are widely appreciated. Even so, there is increasing awareness that publication practice sometimes falls well short of the goal of transparency that supports a thorough evaluation of the results, sufficient information for research synthesis, and the possibility of replicating of a study."
"Reproducibility",2058978358,"2303845125; 2119616764","Yun He; Chris H. Q. Ding","reproducibility; distributed memory; scalability; rounding; theoretical computer science; operator; computer science; parallel computing",2000,"Conference",NA,"ACM","10.1145/335231.335253","Using accurate arithmetics to improve numerical reproducibility and stability in parallel applications",9,"Numerical reproducibility and stability of large scale scientific simulations, especially climate modeling, on distributed memory parallel computers are becoming critical issues. In particular, global summation of distributed arrays is most susceptible to rounding errors, and their propagation and accumulation cause uncertainty in final simulation results. We analyzed several accurate summation methods and found that two methods are particularly effective to improve (ensure) reproducibility and stability: Kahan's self-compensated summation and Bailey's double-double precision summation. We provide an MPI operator MPLSUMDD to work with MPI collective operations to ensure a scalable implementation on large number of processors. The final methods are particularly simple to adopt in practical codes."
