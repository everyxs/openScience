{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "active": "ipynb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jovyan/ReproducibilityDemo/code-data', '/srv/conda/lib/python37.zip', '/srv/conda/lib/python3.7', '/srv/conda/lib/python3.7/lib-dynload', '', '/home/jovyan/.local/lib/python3.7/site-packages', '/srv/conda/lib/python3.7/site-packages', '/srv/conda/lib/python3.7/site-packages/IPython/extensions', '/home/jovyan/.ipython', '/home/jovyan/.local/lib/python3.6/site-packages/']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['configuration', 'credentials']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install --upgrade pip --user\n",
    "#!pip install configparser --user\n",
    "import os, sys\n",
    "import configparser\n",
    "sys.path.append('/home/jovyan/.local/lib/python3.6/site-packages/')\n",
    "print(sys.path)\n",
    "\n",
    "os.path.abspath(\"AzureDownload/config.txt\")\n",
    "os.getcwd()\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"/home/jovyan/AzureDownload/config.txt\")\n",
    "config.sections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "active": "ipynb"
   },
   "outputs": [],
   "source": [
    "## Required for Azure Data Lake Analytics job management\n",
    "#!pip install azure-mgmt-datalake-analytics --user\n",
    "from azure.mgmt.datalake.analytics.job import DataLakeAnalyticsJobManagementClient\n",
    "from azure.mgmt.datalake.analytics.job.models import JobInformation, JobState, USqlJobProperties\n",
    "from azure.common.credentials import ServicePrincipalCredentials\n",
    "\n",
    "credentials = ServicePrincipalCredentials(client_id =config.get(\"credentials\",\"client\"), secret=config.get(\"credentials\",\"password\"), tenant =config.get(\"credentials\",\"tenant\"))\n",
    "\n",
    "subid= 'Microsoft Azure Sponsorship'\n",
    "rg = 'IUNI-MAG-RG'\n",
    "location = 'eastus2'\n",
    "adla = 'iunimag'\n",
    "\n",
    "adlaJobClient = DataLakeAnalyticsJobManagementClient(credentials, 'azuredatalakeanalytics.net')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After seting up the environement and Azure crendentials, we submit a u-sql script to run on Azure Datalake Analytics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "active": "ipynb"
   },
   "outputs": [],
   "source": [
    "import logging, getpass, pprint, uuid, time\n",
    "script = open(\"/home/jovyan/openScience/code-data/usql-scripts/MAGgetOld.usql\", \"r\")\n",
    "\n",
    "jobId = str(uuid.uuid4())\n",
    "jobResult = adlaJobClient.job.create(\n",
    "    adla,\n",
    "    jobId,\n",
    "    JobInformation(\n",
    "        name='MAGgetOld@jupyter',\n",
    "        type='USql',\n",
    "        degree_of_parallelism=15,\n",
    "        properties=USqlJobProperties(script=script.read() )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "active": "ipynb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes 1.569260597229004 seconds to download Open-old.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from azure.storage.blob import BlockBlobService\n",
    "\n",
    "CONTAINERNAME ='mag-2019-03-02'\n",
    "BLOBNAME= \"Open-old.csv\"\n",
    "LOCALFILENAME= \"/home/jovyan/openScience/code-data/Open-old.csv\"\n",
    "\n",
    "#download from blob\n",
    "block_blob_service=BlockBlobService(account_name=config.get(\"configuration\",\"account\"),account_key=config.get(\"configuration\",\"password\"))\n",
    "#download from blob\n",
    "t1=time.time()\n",
    "block_blob_service.get_blob_to_path(CONTAINERNAME,BLOBNAME,LOCALFILENAME)\n",
    "t2=time.time()\n",
    "print((\"It takes %s seconds to download \"+BLOBNAME) % (t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "active": "ipynb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes 0.9228744506835938 seconds to download Reproduce-old.csv\n"
     ]
    }
   ],
   "source": [
    "BLOBNAME= \"Reproduce-old.csv\"\n",
    "LOCALFILENAME= \"/home/jovyan/openScience/code-data/Reproduce-old.csv\"\n",
    "\n",
    "#download from blob\n",
    "t1=time.time()\n",
    "block_blob_service.get_blob_to_path(CONTAINERNAME,BLOBNAME,LOCALFILENAME)\n",
    "t2=time.time()\n",
    "print((\"It takes %s seconds to download \"+BLOBNAME) % (t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the output tables downloaded, we proceed to parse the inverted-indexed abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse(inputStr):\n",
    "  if pd.isna(inputStr):\n",
    "    return None\n",
    "  s = eval(inputStr)\n",
    "  List = list()\n",
    "  for word in s['InvertedIndex'].keys():\n",
    "    for index in s['InvertedIndex'][word]:\n",
    "        List.append((word, index))\n",
    "  List.sort(key=lambda x: x[1], reverse=False)\n",
    "  article = [i[0] for i in List]\n",
    "  article = ' '.join(article)\n",
    "  return article\n",
    "  pass\n",
    "\n",
    "#eval(open.iloc[3]['IndexedAbstract'])['InvertedIndex']['Research']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AuthorIds               7907\n",
       "AuthorNames             7907\n",
       "AuthorOrders            7907\n",
       "AuthorPapers            7907\n",
       "FoSNames                7907\n",
       "FoSPaperCounts          7907\n",
       "FoSCiteCounts           7907\n",
       "DisplayName             5586\n",
       "NormalizedName          5586\n",
       "PaperId                 7907\n",
       "Rank                    7907\n",
       "Doi                     4961\n",
       "DocType                 4393\n",
       "JournalId               5586\n",
       "ConferenceInstanceId     109\n",
       "OriginalTitle           7907\n",
       "Year                    7907\n",
       "Date                    7907\n",
       "Publisher               5675\n",
       "ReferenceCount          7907\n",
       "CitationCount           7907\n",
       "EstimatedCitation       7907\n",
       "URLs                    7286\n",
       "IndexedAbstract         3642\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open = pd.read_csv('Open-old.csv', delimiter=\"\\t\")\n",
    "open = open[open['AuthorIds'].notnull()]\n",
    "open['IndexedAbstract'] = open['IndexedAbstract'].map(parse)\n",
    "\n",
    "rep = pd.read_csv('Reproduce-old.csv', delimiter=\"\\t\")\n",
    "rep = rep[rep['AuthorIds'].notnull()]\n",
    "rep['IndexedAbstract'] = rep['IndexedAbstract'].map(parse)\n",
    "#rep.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicate records from both data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "openSet = set(open.PaperId)\n",
    "repSet = set(rep.PaperId)\n",
    "overlap = openSet.intersection(repSet)\n",
    "cover = openSet.union(repSet)\n",
    "len(cover)\n",
    "open = open[~open[\"PaperId\"].isin(overlap)]\n",
    "rep = rep[~rep[\"PaperId\"].isin(overlap)]\n",
    "#rep.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally we sort the AuthorIds, AuthorNames according to AuthorOrders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Strip(x):\n",
    "  return x.strip()\n",
    "\n",
    "def SortAuthors(row):\n",
    "  ids = list(map(Strip, row['AuthorIds'].split(\";\")))\n",
    "  names = list(map(Strip, row['AuthorNames'].split(\";\")))\n",
    "  orders = list(map(Strip, row['AuthorOrders'].split(\";\")))\n",
    "  \n",
    "  Tup = list()\n",
    "  for i in range(0,len(ids)):\n",
    "    Id, name, order  = ids[i], names[i], orders[i]\n",
    "    Tup.append((Id, name, order))\n",
    "  \n",
    "  Tup = list(set(Tup))\n",
    "  Tup.sort(key=lambda x:x[2], reverse=False)\n",
    "  \n",
    "  sortedIDs = \"\"\n",
    "  flag = 1\n",
    "  for Id, name, order in Tup:\n",
    "    if flag == 1:\n",
    "      sortedIDs += Id\n",
    "      flag = 0\n",
    "    else:\n",
    "      sortedIDs += \"; \"\n",
    "      sortedIDs += Id\n",
    "        \n",
    "  sortedNames = \"\"\n",
    "  flag = 1\n",
    "  for Id, name, order in Tup:\n",
    "    if flag == 1:\n",
    "      sortedNames += name\n",
    "      flag = 0\n",
    "    else:\n",
    "      sortedNames += \"; \"\n",
    "      sortedNames += name\n",
    "  \n",
    "  return pd.Series([sortedIDs,sortedNames])\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AuthorIds               3499\n",
       "AuthorNames             3499\n",
       "AuthorOrders            3499\n",
       "AuthorPapers            3499\n",
       "FoSNames                3499\n",
       "FoSPaperCounts          3499\n",
       "FoSCiteCounts           3499\n",
       "DisplayName             1977\n",
       "NormalizedName          1977\n",
       "PaperId                 3499\n",
       "Rank                    3499\n",
       "Doi                     2375\n",
       "DocType                 1049\n",
       "JournalId               1977\n",
       "ConferenceInstanceId      64\n",
       "OriginalTitle           3499\n",
       "Year                    3499\n",
       "Date                    3499\n",
       "Publisher               1473\n",
       "ReferenceCount          3499\n",
       "CitationCount           3499\n",
       "EstimatedCitation       3499\n",
       "URLs                    3335\n",
       "IndexedAbstract         1452\n",
       "AuthorIdsOrder          3499\n",
       "AuthorNamesOrder        3499\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted = open.apply(SortAuthors, axis=1)\n",
    "open['AuthorIdsOrder'] = sorted[0]\n",
    "open['AuthorNamesOrder'] = sorted[1]\n",
    "\n",
    "sorted = rep.apply(SortAuthors, axis=1)\n",
    "rep['AuthorIdsOrder'] = sorted[0]\n",
    "rep['AuthorNamesOrder'] = sorted[1]\n",
    "#open.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "open.to_csv('Open.csv',index=False, encoding='utf-8')\n",
    "rep.to_csv('Reproduce.csv',index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if the author count remains the same after the re-ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "active": "ipynb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "openTest = pd.read_csv('Open.csv')\n",
    "compare1 = openTest.AuthorIdsOrder.str.count(\"; \")\n",
    "compare2 = openTest.AuthorIds.str.count(\"; \")\n",
    "result = pd.concat([compare1,compare2],axis=1).astype(np.float16)\n",
    "result['AuthorIdsOrder'].equals(result['AuthorIds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "active": "ipynb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openTest = pd.read_csv('Reproduce.csv')\n",
    "compare1 = openTest.AuthorIdsOrder.str.count(\"; \")\n",
    "compare2 = openTest.AuthorIds.str.count(\"; \")\n",
    "result = pd.concat([compare1,compare2],axis=1).astype(np.float16)\n",
    "result['AuthorIdsOrder'].equals(result['AuthorIds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
